- 2014-05-27 鹿島先生
  - 後は前処理
  - 基底をどう取るかは前処理の問題
  - Random Forest 最強説

- 2014-05-23 鹿島先生
  > PRMLをチラ見して載っているレベルでも、
  > 線形モデル： 線形回帰、リッジ回帰
  > 非線形モデル： カーネル回帰、Nadaraya-Watson
  > など、簡単に試せるものがあります。

- 大枠
  - Bayesian Ridge Regression — scikit-learn 0.14 documentation
    http://scikit-learn.org/stable/auto_examples/linear_model/plot_bayesian_ridge.html#example-linear-model-plot-bayesian-ridge-py
  - deep learning
  - [X] random forest regression
  - [ ] 共分散分析で離散と連続の混在データを処理できる?
  - [ ] カーネル回帰
  - [ ] Nadaraya-Watson

- [ ] 誤差関数、離れたときに抑えたい
  二乗誤差はでかい

4カラム目、9カラム目で4通りに分けて回帰するかな…
[00][01][10][11]

環境
- [X] python チュートリアル
- [X] numpy

書籍
- [X] Pythonによるデータ分析入門 : NumPy、pandasを使ったデータ処理

* 記録
RidgeCV -1化, 二乗利用, 平均正則化all, 平均計算withTEST

253行
/5.0 = 50次元まで耐えられる?

元の次元  16
二乗利用 +14 (30)
{1,0} を {{1,0},{1,0}} にコーディング +2
三乗利用 +14 
ラッソ

1.14. Isotonic regression — scikit-learn 0.14 documentation
http://scikit-learn.org/stable/modules/isotonic.html#

RandomForests

Random Forests祭り @名古屋CVPRML勉強会
http://www.slideshare.net/hironobufujiyoshi/04-randomforests1116



- [X] 前処理
  - [X] 正規化
  - [X] 白色化

- [ ] ノイズパラメータをCVで除去

- 行列 を並べ替え or 抽出
- 左側だけfit
- 左側だけtransform

- [ ] パラメータ調整
  - [ ] トレーニングデータ集合をサブセットに分割 T
    - サブセット間で若干重複がある程度の数が良い
    - 「若干」？
  - [ ] ＝? 木の数 (n_estimators)
    - 大きいと表現能力が上がる
    - # …大きい方が良い?

  - [ ] 分岐関数候補 K = 分岐ノード候補数 = 1つ1つの決定木 (max_features)
    - [ ] 特徴ベクトルの次元数のsqrt程度が良い?
    - 多くすると、学習時間が増加するが識別性能が向上
    - グリッドサーチ

  - [ ] 木の深さ (max_depth)
    - 多いほど過学習になる

  - [ ] CVできない?
    - パラメータをグリッドサーチ
      http://d.hatena.ne.jp/shakezo/20121221/1356089207

- ロバスト化
  - 済

| RandomForest(n_e:150), クラス分離             | 14.362329 |
| RandomForest(n_e:150, m_d:10), クラス分離     | 14.638701 |
| RandomForest(n_e:250), クラス分離             | 14.639562 |
| RandomForest(n_e:500), クラス分離             | 14.888834 |
| RandomForest(n_e:250), 平均正則化, クラス分離 | 15.080715 |
| RandomForest(n_e:150)                         | 15.144029 |
| RandomForest(n_e:100), クラス分離             | 15.199334 |
| RandomForest(n_e:150), 二乗利用               | 15.341536 |
| RandomForest(n_e:150), 平均正則化             | 15.890994 |
| RandomForest(n_e:150, max_features='sqrt')    | 17.985183 |

| RidgeCV 二乗利用, クラス分離, 平均正則化, 平均計算withTEST         | 22.151482 |
| RidgeCV 二乗利用, クラス分離, 平均正則化, 平均計算withTEST, 白色化 | 25.971049 |
| RidgeCV 二乗利用, クラス分離, 平均正則化, 平均計算withTEST         |   21.5945 |
| RidgeCV 二乗利用, 平均正則化all, 平均計算withTEST                  | 22.889570 |
| RidgeCV -1化→正規化(修正前)                                       | 32.132395 |
| RidgeCV 平均正則化all, 平均計算withTEST                            | 32.173160 |
| RidgeCV 平均正則化all                                              | 32.588716 |
| RidgeCV                                                            | 32.204174 |
| RidgeCV 正規化, -1化                                               | 42.643828 |
| RidgeCV 平均正規化, -1化                                           | 32.887347 |
| 線形 -1化→正規化(修正前)                                          | 32.299799 |
| 線形 正規化                                                        | 43.645649 |
| 線形                                                               |   32.3716 |
| SVR GridSearch CV                                                  | 39.506073 |
| SVR                                                                | 98.252059 |

- [ ] 0,1もまとめて平均正規化(Z(0,1))してみよう
  ロバストになりそう
- [ ] 平均・分散を test/train まとめる?
  [3]
  train 0.0830039525692
  test  0.0553359683794
- [ ] -1化
  修正前の「正規化 -1化」は、{1,0}→{3,-1} くらいの感じだなぁ…
  とりあえず{1,0}→{1,-1}は効きそう? これだけ残してやってみよう
- [ ] {1,0} を {{1,0},{1,0}} にコーディングする?
- [ ] 正規化
  …がいまいち効いていない
- [ ] RidgeCV
  範囲もう少しどうにかする?
  引数の意味が分かっていない
  なぜ正規化が効かないのだ(げっそり)

* ref
今さら人に聞けない「重回帰分析の各手法の使い分け」 - 銀座で働くデータサイエンティストのブログ
http://tjo.hatenablog.com/entry/2013/09/18/235052

連続型変数とカテゴリカル変数を混在させる
http://www.hucc.hokudai.ac.jp/~s16802/toukeizemi2011/toukei9.pdf

配列操作の比較表: Ruby, Python, JavaScript, Perl, C++ - bkブログ
http://0xcc.net/blog/archives/000043.html

scikit-learnでサポートベクトル回帰、及びそのパラメーター推計 with クロスバリデーションやってみる - My Life as a Mock Quant
http://d.hatena.ne.jp/teramonagi/20130825/1377434479

2013.07.15 はじパタlt scikit-learnで始める機械学習
http://www.slideshare.net/moa108/20130715-lt-scikitlearn

入門機械学習の線形回帰をscikit-learnでやってみる
http://blog.kzfmix.com/entry/1370250876

scikit-learnを用いた機械学習チュートリアル
http://www.slideshare.net/AtsushiKanaya/scikitlearn

pythonの機械学習ライブラリscikit-learnの紹介 - 唯物是真 @Scaled_Wurm
http://sucrose.hatenablog.com/entry/2013/05/25/133021

