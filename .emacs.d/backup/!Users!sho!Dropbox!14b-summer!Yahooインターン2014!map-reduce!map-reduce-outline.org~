* 大規模データの分散処理 (Hadoop がどう便利なのかを知る)
- 巨大なデータを <==> 小規模データ
- 汎用計算機からなる大規模クラスタ上で <==> 汎用計算機単体, スパコン単体
- 分散処理する <==> 逐次処理
のためのプラットフォーム

メリット
- 分散処理による高速化
- プロセス間通信や障害時対応

制約
- ファイルサイズが非常に大きい
- 稀にしか更新されない

x オンライン焦点の売り上げ管理
  データベース照会を伴うから
  - [ ] …なぜダメなのだ??

利用例
- Google PageRank 行列とベクトルの乗算

** 経緯
なぜ「　　　」が必要か
- textp.19冒頭 (よく分からん)
- どういう処理を高速化するのか
  - 検索
    - Web ページのランキング
    - [ ] PageRank…
  - 

- 計算環境の変遷
  専用並列計算機 (多数のプロセッサと特殊なハードウェアからなる)
  ==> 独立した計算ノード(ありふれたハードウェア)

** 分散処理の仕組み

|                        | Google 基盤ソフトウェア  | Hadoop (OSS版クローン)                |
|------------------------+--------------------------+---------------------------------------|
| 分散処理フレームワーク | MapReduce                | Hadoop MapReduce Framework            |
| 分散ファイルシステム   | Google File System (GFS) | Hadoop Distributed File System (HDFS) |

** 物理的な構成 (2.1.1)

** 分散ファイルシステム (distributed file system, DFS) (GFS, HDFS)
*** 特長
- <==> ディスクブロック ???
- 既存のOSで用いられるディスクブロックより大きな単位を扱える
  - [ ] ディスクブロック?
- データの冗長化
  - 物理的な障害への耐性
  - [ ] p.19 では「メディアの障害」になってるなぁ
p.21
- 巨大
- ファイルの更新は稀、読み込みと追加は発生

- ファイルはチャンク (chunk) に分割される

** 分散処理フレームワーク (MapReduce)
- <==> 逐次処理
- 並列計算の方法論
- 計算途中でのハードウェア障害への耐性
  - [ ] どういうこと?

*** key-value pair
連想配列、辞書(dictionary) …に似ているデータ構造だが、
key は一意でなくて良いという点で決定的に異なる
データセットにこの構造を持たせる必要がある

*** Map
- key, value のペアを作る (@IT)

- 多くの場合入力のkeyは重要ではない
- 複数の MapReduce 処理の結合の都合上


- (k,v) ==> [(k,v)]
  - (k,v) から中間的な(k,v)(リスト?)を生成 (デザパタ)


- マスターノードは入力データを受取、

- コンバイナー (text 2.2.4)

*** Shuffle
(text)
- keyによるグルーピング
- {(k,v)}がマスターコントローラによって集められ、keyを使ってソートされる。同じkeyを持つ(k,v)は同じreduceタスクに分配される 
- r個reduceタスクが存在するなら、keyに対して{0,...,r-1}のバケツ番号をhash関数で振り分け
  - [ ] タスク=ノード?

- グルーピング (grouping) : hash関数で分類
- 集約 (aggregation) : [(k,v_i)] ==> (k,[v_i])

- 同じkeyを持つペアを束ねる (@IT)

*** Reduce
(text)
- 1回につき1個のkeyを処理。keyに関連づけられたすべての「valueを何らかのやり方で結合する」

- 「処理」(処理て…) (@IT)
- (k,[v]) ==> [(k,v)] (デザパタ)
  - [ ] 1ペアに対する出力が複数の場合もあるの?

(text)
reduce関数の多くが結合性と可換性を満たす場合は、
reduce処理の一部をmap-phaseで実行可
- [ ] ん… 満たさない場合、つまり順番に意味がある場合があるとして、それはgrouping-phaseでどうにかしてくれるの?

*** 2.2.5
ファイルはチャンクに分けられる

- マスターコントローラープロセス
- ワーカープロセス
  - Map worker
  - Reduce worker

…を異なる計算ノード上にforkする


** MapReduce処理の例
*** 文書集合からの各語の出現回数のカウント
- map
  - 入力: 文書
  - 出力: [(w,1)]
