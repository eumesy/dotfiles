2014/03/14 1000-1200

先生、和光市にお住まい

- 人工知能の各分野(e.g. オントロジー、論理学、機械学習)についての知見が必要

* 推論とNLP
** NLP研究者の興味
- NLPの研究をしている人
  - 半数は実用に興味が(?)ある Siri, Web
  - 半数は知能に興味がある
 
** (自然言語に推論は表れるか?)
- 言語抜きには考えられない
- _少なくとも入力/出力は言語_
  - _ここからモデルを立てる_
- 脳の局所的な活動を解剖しても分からない
  - Deep Learning は脳の活動を表している(?)と言われるが、あれも局所的活動(?)

** NLPの歴史
- 80s
  - あまりうまくいっていなかった
  - 実際の empirical な大きなデータに基づいて再現しようとしていなかった
  - _言語はひとつの数式で表現できるような簡単なものではない_
  - 自然言語処理は色々なモデル/技術が必要 単純なものではない
  - 背景知識、hogehoge解析、mogamoga解析、文脈、論理的関係 など色々なモデル/技術を組み合わせないといけない
  - 理屈だけではダメ(?) 実際に計算機で動かすと全然うまくいかない
- 90s以後
  - 構文解析
    - 結構大変
    - NPLのトップの人たちがよってたかって精度を上げた
    - 2000年代に徐々にできるようになってきた
      - 90%くらいだが
      - 十分実用的なレベルになった
      - _意味理解の入り口ができた_
- いま
  - _意味/推論にシフトしてきている_
  - いままでは意味表現ができなかった

- CSでは「意味」はタブーだった
- 50代60代の研究者は身に染みている
  - 第五世代コンピュータに関わった
    - 人工知能
    - 機械翻訳
    - 莫大な予算がつぎ込まれた
- だけどこれは仕方ない
  - 手持ちの道具はPrologしか無かった
  - 記号＋統計の道具が無かった
  - 機械学習も無かった
  - 単純な推論がいかに難しいか、認識されていなかった

- それぞれの細分化された分野で、できること、整理できることの研究が進められて来た
  - オントロジー (山口先生ら)
  - 論理学
  - 機械学習
    - linear classifier(線形分類器)
      - できることはできる、できないことはできない
    - deap learning
- いま戻って来ている

- 勝手な予測だが、これらを繋ぐのが大事になると思っている
  # 各分野についての知見が必要、ということね
- 色々なタイプを
- 高速にまとめる

- 今のトレンド(?)
  - 機械学習
  - 動くものを

** 含意関係認識
- 含意関係認識は2000年代半ば〜
- (新井先生からも紹介があったかもしれないが)
  例えば世界史の問題、正しい文を選びたい
- 教科書に答えは書いてある、が、違う書き方。文字列として全く違う

- 人間は同じことを表すのに色々な表現を使う
- (NLPの話からは外れるが) どんな猫画像を見ても、猫と分かる
- _人間の処理を挟むと同じと判断される_
- 人にとっては簡単
- _この「同じ」が認識の世界で一番大事_

- 「同じ」であることが意味理解の基礎
  - _意味の世界の1割にも満たない_
- しかしこれだけでも応用例ある
  - 単純な質問応答
  - 正誤判定
  - 質もOKだし(?)、計算量に耐えられるマシンもでてきた(?)
- その先には 理由・因果関係
  - 言語より一段抽象度が高い
- あるいは(?)要約
- _100年後200年後に本当の意味理解ができるようになるかもしれない_

- 人間の「同じ」には、「論理的に同じ」以外に(?)、「だいたい同じ」というゆるい判断がある
- 「皇帝直属の軍」＝「国の軍」はそんなに自明じゃない
- 「皇帝」について知っていないといけない
- 「皇帝」には「国」が紐づく
- (明示的に表されない)「国」はどこか
- 対立する国などが出て来たら、ひとつの文に国がポコポコ出てくることになる
- ここでは分かりやすい例を出したが、実際はもっと混沌としている

- 含意関係認識には色々なアプローチがある
  - feature ==> 分類 はあまり面白くない
  # ??

** (意味を考えようとしたときの) NLPの難しさ (論理と統計の結びつけかた)
- 論理的関係(記号)と、ゆるい話(deep learningとかでやる)をどう組み合わせるかは重要な問題
- あまりうまくできなかった
- くっつけられるモデルはまだできたばかり
- 自分たちは(?)、FOLのちょっと弱い(が高速に計算できる)サブセットの上で、統計モデルを立てている
  - exist/any 以外の量化子もたくさんある
    - 「多くの」とか
      # そうそう!!
    - Generalized Quantier
  - ＋時間の論理
  - ＋状態(だったっけ…?)の論理
    # 様相論理?

- _一階述語論理は、我々が一瞬で分かる"推論"に比べて"強"すぎる_
  - 一階述語論理で表せる多くの論理式は我々にとって難しすぎる(?)
    # 量化子の数の話?
  - これは僕たちの扱いたい推論ではない
  - 僕たちがやりたいのは定理証明ではない
- 一階述語論理に(機能を?)追加していくとどんどん _重くなる_
- 普通の人が一瞬で分かる"意味の同値類"はもっと狭い

- いま、命題論理のサブセットくらいになっている
  - = 速い
- 関係代数のサブセットであるDCSという意味表現
- Description Logic
  - (概念の定義・表現に優れた論理) http://mhjcc3-ei.eng.hokudai.ac.jp/~yoshioka/kb/kby-1.pdf
- 変数も量化子も無い
  # ???

- (重さや濃淡は?)
  - スコアは付けられる

- 今問題はスピードでなく精度
- _人間が瞬時にざっくりとやっている推論、おそろしく難しい_
  - パラフレーズ
  - ゆるい推論
- あれもこれも、どうやって組み合わせれば良い？
- 高速かつ、色々な機械学習と組み合わせる

- FOL
  - 便利
  - 遅い

- (Markov Logic?)
  - 各モデルについて確率が定義されている
  - FOLと同じなので計算は遅い
    - そのまま含意に使うのは難しい
    - スピードを出そうとすると機能を排除する必要がある
- x 人間的推論を達成するフレームワーク
- o タスクの性質を記述するのに便利
  - プログラム言語みたいなもの
  - Prologのようなもの
- 確率を学習させる
  - 構文解析で使う(?)

- 論理＋統計(確率?)は色々あるが、基本的には一階述語論理ベース
- 昔はProlog＋確率もあった
  - 80s, 90s

- 「意味をやりたい」という学生が来た場合は、
  「意味って何？」と問いつめて、諦めてもらうようにしている
  (= 一足飛びにはいかない?)

* NLPの研究者
- 宮尾先生
  - 私は、原理主義的
  - 普通の人はLogicやりたくない
  - 入り口から入るような
  - 根っこを考える
  - 出口が見えない
  - つらい

- 松崎さん
  - 東大ロボットの数学のソルバのかた
  - NLP以外＋NLPでちゃんと作って、ちゃんと答えを出す
  - 係り受け解析以後は全部論理
  - 数式処理ソフトの投げる
  - 80sに見た夢
  - 数学だから動く

- NIIのスタンスは、BS日テレでやっていた特番で結構ちゃんと放送していた
  - ネットにあがっているかも

- 田さん(助教)
  - 「含意関係認識は全部この人がやっている」
  - 4月から乾研の特任助教になる
  - 東大数学卒
  - 一度投資銀行(?)に入ったが、新井先生の講演を聞いて、人工知能をやりたいから雇ってほしいと言ってきた

- 黒橋先生と乾先生は同じプロジェクト
  # CREST?

- 乾先生
  - NLP業界で一番頑張っている、活躍している
  - たぶん、興味が一番近い
  - 人(スタッフ)がたくさん居る
    - 含意をやっている人も居るけれど、機械学習をやっている人も

- 黒橋先生
  - 言語の基礎技術に興味を持っている
  - また、かなり empirical
    - 具体的なアプリケーションに興味がある
      - コールセンターとか
    - 実際に動くものを作る

- 山本章博先生
  - 言語というより論理の人
  - 論理の人たちは、言語の中でも(?)とくに論理の部分だけを扱おうとしている
  - cf. NLPの人は、色々なことをくっつけたがる
    - 「こんなエラーがあったかー」とか言って喜ぶ

- 五十嵐先生
  - さらに突き詰めた興味の人

- NAIST
  - 機械学習
  - 言語学

** (推論をやっている外国の先生?)
- Ido Dagan @イスラエル
  - http://u.cs.biu.ac.il/~dagan/
  - 含意と言えばこの人
  - RTEも2010年くらいまでは流行ってた
    - 研究はひとつのイシューにフォーカスしたい
    - cf. 含意関係認識
      - ひとりでやるのは不可能
      - グループでやる必要がある

- RTEに関連して
  - Johan Bos (研究者) http://www.rug.nl/staff/johan.bos/
    - Logicの人(?)
  - semantic text similarity (タスク?)

- Eduard Hovy @CMU
  - abduction

- アメリカは empirical
  - 大きなプロジェクト
  - 成果が求められる
  - 軍関係のお金
- MIT
- USC (University of Southern California)

- 日本にも empirical な人 (は居る?)(が多い?)

- DFKI
  - Das Deutsche Forschungszentrum fur Kunstliche Intelligenz GmbH
  - ドイツ人工知能研究センター
  - ヨーロッパで一番でかい
  - ちょっと前は(含意を?推論を?)やっている人居た

- Cambridge
- Oxford

- AI方面は山本章博先生の方が詳しいだろう

- 機械学習の人は、アプリケーションがあると寄ってくる

* 大学院個別の情報
** 入試
- CSとAIの基礎を学んでおけば大丈夫
- 基本は口頭試問。例えば計算量の話などを答えさせて、答えられなければ「うーん」となる

** 大学院生活、環境
- 基本的に「これがやりたい」と研究テーマが決まっている学生が来る
  - いきなり研究
  - 系統だった教育はしていない
    - cf. NAIST
  - 論文等の指導はする
- 講義
  - 単位はそんなに大変じゃない
  - (総研大の講義は総じて?) 平均聴講者3人とか
  - 自分の好きなところを紹介する形になる
  - 私(宮尾先生)もこんなマニアックな講義をしているのは自分だけだと思ってやっている
  - ので、基礎が無いと辛い
- 構成員
  - 先生1, ポスドク4, 学生4
  - _論文のドラフトは、皆に回して皆で見る、(手が空いていれば)突っ込む_
  - 所謂わいわいした学生生活ではない
  - 先生の部屋、ポスドクの部屋、研究事務(?)の人の部屋などが分かれている
    - お互い滅多に合わない
    - 週1の打ち合わせだけ(?)
  - 院生室は相澤研と一緒
    - 東大のB4〜M2の学生が来ている
- (自然言語処理に限らなければ?) 広く人工知能に興味がある人は建物内にたくさん居る
  - 隣の部屋はオントロジーの大御所

* 進路
** (「Ph.D.のapplyが通ったので抜けます」は)
- 別に構わない
- (いま?)D1で留学予定の人も居る
- 基本は博士一貫5年だが、特別な事情があれば、審査の上で修士号を出す事もできる

** (年齢?)
- アカデミックな世界では、論文(の質? 貢献度?)につきる

* 今すべき勉強
- CSの基礎は絶対必要
  - 離散数学
  - プログラミングの技術
- 人工知能
  - 探索とか
- 確率・統計・機械学習記号論理学
- 形式言語理論
  - CFG(文脈自由文法)
    - CYKアルゴリズム (CYK法 - Wikipedia http://ja.wikipedia.org/wiki/CYK%E6%B3%95)
      - 構文解析アルゴリズム
  - PCFG(確率文脈自由文法)
    - 基本中の基本
    - 『エージェントアプローチ 人工知能』の23章に載ってる
    - "Models of Computation and F..."
      # ???
