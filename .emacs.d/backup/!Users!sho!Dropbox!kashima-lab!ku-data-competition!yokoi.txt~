* 試した手法
- ライブラリ
  - python + numpy + scikit-learn

- モデル
  - 線形回帰
  - リッジ回帰
  - サポートベクトル回帰
  - Random Forests

* 前処理 カテゴリカル変数
- そのまま利用
- {0,1} → {-1, 1}
- {0,1} → {(0,1), (1,0)}

* 前処理 連続値変数
- 正規化
  - 平均を引く (平均を0に)
  - 標準偏差で割る (分散を1に)
  - 両方 (~N(0,1) な気持ち)

- 平均および分散を、トレーニングデータ＋テストデータ両方から求める

- 白色化

- 各連続値変数の二乗値を変数に加える
  - 二次の項をすべて加えるわけではなく、x_1^2, x_2^2, x_3^2, ... のみ加えた
  - 二次の項をすべて加えると、データ数が、変数の次元の5〜10倍に対して小さくなるため
- 各連続値変数の三乗値を変数に加える

* 線形回帰、リッジ回帰
- 正規化 
  - 平均を引く (平均を0に)
  - 標準偏差で割る (分散を1に) △
  - 両方 (~N(0,1) な気持ち) ○
- 平均および分散を、トレーニングデータ＋テストデータ両方から求める ○

- 白色化 ×

- {0,1}
- {0,1} → {-1, 1} △
- {0,1} → {(0,1), (1,0)} ○

- 連続値変数の二乗値を利用 ○
- 連続値変数の三乗値を利用 ×

* SVR
- 微妙
- ガウシアンカーネル
- パラメータの Cross Validation を入れても、線形回帰以下

* Random Forests
- {0,1} → {(0,1), (1,0)} ○

- 正規化 
  - 平均を引く (平均を0に)
  - 標準偏差で割る (分散を1に)
  - 両方 (~N(0,1) な気持ち) ○
- 平均および分散を、トレーニングデータ＋テストデータ両方から求める ○

- 生成する木の数
  - 150 ○
  - 250 △
  - 500 △
  - 100 ×

- 木の深さに上限を設ける
  - 10 △
  - 上限なし ○

* できなかったこと、次回への課題
- 試している手法の妥当性を(公式サイトへの提出以外での方法で)チェック
- パラメータの Cross Validation

- ノイズ変数の除去
  - 適当な変数を除いて提出した結果を見る?
  - (正規化した後に) 線形回帰の係数で見る?
    - 「線形回帰が効きそう」ということだったので…
  - 適当な基準で見つけられる? (AIC等)

- 前処理として、カテゴリカル変数 x 連続値変数 などの値を入れる
